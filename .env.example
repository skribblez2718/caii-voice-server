# CAII Voice Server Configuration

# Server Configuration
HOST=127.0.0.1
PORT=8001

# API Key Authentication (optional - if not set, auth is disabled)
# Generate a secure key: python -c "import secrets; print(secrets.token_urlsafe(32))"
VOICE_SERVER_API_KEY=

# TTS Model Paths (Qwen-TTS)
# Update these paths to match your model locations
TTS_BASE_MODEL_PATH=/path/to/Qwen3-TTS-12Hz-1.7B-Base
TTS_VOICE_DESIGN_MODEL_PATH=/path/to/Qwen3-TTS-12Hz-1.7B-VoiceDesign

# STT Model Configuration (Faster-Whisper)
# Model options: tiny, base, small, medium, large-v2, large-v3, turbo
# Default: base (good balance of speed/accuracy, ~145MB)
STT_MODEL_NAME=base

# Device for STT inference
# Options: cuda (GPU), cpu, auto (auto-detect)
# Default: cuda
STT_DEVICE=cuda

# Compute type for STT inference
# Options: int8 (fastest), int8_float16, float16 (most accurate), auto
# Default: float16
STT_COMPUTE_TYPE=float16

# Beam search width - higher = more accurate but slower
# Range: 1-10, Default: 5
STT_BEAM_SIZE=5

# Number of candidate sequences to consider
# Range: 1-10, Default: 5
STT_BEST_OF=5

# Voice Activity Detection - skip silence for faster inference
# Options: true, false, 1, 0
# Default: true
STT_VAD_FILTER=true

# Rate Limiting
RATE_LIMIT_REQUESTS=10
RATE_LIMIT_WINDOW_SECONDS=60

# Model Offloading
# Automatically moves TTS models to CPU after idle timeout to free ~10GB GPU memory
MODEL_OFFLOAD_ENABLED=true
MODEL_IDLE_TIMEOUT_SECONDS=300
MODEL_OFFLOAD_CHECK_INTERVAL_SECONDS=60
